{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/poa/Library/Python/3.9/lib/python/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in /Users/poa/Library/Python/3.9/lib/python/site-packages (4.49.0)\n",
      "Requirement already satisfied: fair-esm in /Users/poa/Library/Python/3.9/lib/python/site-packages (2.0.0)\n",
      "Requirement already satisfied: biopython in /Users/poa/Library/Python/3.9/lib/python/site-packages (1.85)\n",
      "Requirement already satisfied: filelock in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: fsspec in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: jinja2 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: requests in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.10)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch transformers fair-esm biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import esm\n",
    "from Bio import SeqIO\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESM2(\n",
       "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0-32): 33 x TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model and its alphabet using fair-esm\n",
    "# Note: I am not using the tokenizer since the batch_converter from alphabet handles tokenization\n",
    "model, alphabet = esm.pretrained.esm2_t33_650M_UR50D()  \n",
    "batch_converter = alphabet.get_batch_converter()\n",
    "\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ESM2(\n",
       "  (embed_tokens): Embedding(33, 1280, padding_idx=1)\n",
       "  (layers): ModuleList(\n",
       "    (0-32): 33 x TransformerLayer(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (k_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (v_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (q_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (out_proj): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "        (rot_emb): RotaryEmbedding()\n",
       "      )\n",
       "      (self_attn_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "      (fc1): Linear(in_features=1280, out_features=5120, bias=True)\n",
       "      (fc2): Linear(in_features=5120, out_features=1280, bias=True)\n",
       "      (final_layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (contact_head): ContactPredictionHead(\n",
       "    (regression): Linear(in_features=660, out_features=1, bias=True)\n",
       "    (activation): Sigmoid()\n",
       "  )\n",
       "  (emb_layer_norm_after): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=1280, out_features=1280, bias=True)\n",
       "    (layer_norm): LayerNorm((1280,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 16161 sequences\n"
     ]
    }
   ],
   "source": [
    "# Load sequences from FASTA file\n",
    "fasta_file = \"data/uniprotkb_data.fasta\"\n",
    "sequences = {record.id: str(record.seq) for record in SeqIO.parse(fasta_file, \"fasta\")}\n",
    "print(f\"Loaded {len(sequences)} sequences\")\n",
    "\n",
    "# dictionary to store segmented embeddings\n",
    "segmented_embeddings = {}  # key: sequence ID, value: list of embeddings for each segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits a protein sequence into overlapping segments and returns the list\n",
    "def segment_sequence(sequence, window_size=100, stride=10):\n",
    "    segments = []\n",
    "    for start in range(0, len(sequence) - window_size + 1, stride):\n",
    "        segments.append(sequence[start:start + window_size])\n",
    "    return segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed sp|A0A087X1C5|CP2D7_HUMAN: 42 segments\n",
      "Processed sp|A0A0C5B5G6|MOTSC_HUMAN: 0 segments\n",
      "Processed sp|A0A1B0GTW7|CIROP_HUMAN: 69 segments\n",
      "Processed sp|A0AV02|S12A8_HUMAN: 62 segments\n",
      "Processed sp|A0AV96|RBM47_HUMAN: 50 segments\n",
      "Processed sp|A0AVF1|IFT56_HUMAN: 46 segments\n",
      "Processed sp|A0AVI4|TM129_HUMAN: 27 segments\n",
      "Processed sp|A0AVK6|E2F8_HUMAN: 77 segments\n",
      "Processed sp|A0AVT1|UBA6_HUMAN: 96 segments\n",
      "Processed sp|A0FGR8|ESYT2_HUMAN: 83 segments\n",
      "Processed sp|A0FGR9|ESYT3_HUMAN: 79 segments\n",
      "Processed sp|A0JLT2|MED19_HUMAN: 15 segments\n"
     ]
    }
   ],
   "source": [
    "# process each sequence: segment and generate embeddings\n",
    "for seq_id, sequence in sequences.items():\n",
    "    sequence = sequence.upper()  # convert to uppercase\n",
    "    segments = segment_sequence(sequence, window_size=100, stride=10)\n",
    "    seg_embeds = []\n",
    "\n",
    "    for i, seg in enumerate(segments):\n",
    "        # prepare data for batch conversion by assigning a unique name per segment\n",
    "        data = [(f\"{seq_id}_seg{i}\", seg)]\n",
    "        batch_labels, batch_strs, batch_tokens = batch_converter(data)\n",
    "        batch_tokens = batch_tokens.to(device)  # move tokens to GPU if available\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_tokens, repr_layers=[model.num_layers])\n",
    "\n",
    "        # get the final layer representation and mean pool\n",
    "        embedding = outputs[\"representations\"][model.num_layers]\n",
    "        seg_embedding = embedding[0, 1:-1].mean(dim=0)\n",
    "        seg_embeds.append(seg_embedding.cpu().numpy())\n",
    "\n",
    "    segmented_embeddings[seq_id] = seg_embeds\n",
    "    print(f\"Processed {seq_id}: {len(segments)} segments\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the segmented embeddings to a .npy file for later\n",
    "np.save(\"esm2_segmented_embeddings.npy\", segmented_embeddings)\n",
    "print(\"Segmented embeddings saved to esm2_segmented_embeddings.npy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
