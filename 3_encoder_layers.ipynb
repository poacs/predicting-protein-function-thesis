{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a50c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: fair-esm in ./.venv/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: biopython in ./.venv/lib/python3.12/site-packages (1.85)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (79.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in ./.venv/lib/python3.12/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n",
      "True\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch transformers fair-esm biopython scikit-learn pandas\n",
    "\n",
    "import torch\n",
    "print(torch.cuda.is_available())  # should return true\n",
    "print(torch.cuda.get_device_name(0))  # should say T4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import ast  # parses string representations\n",
    "\n",
    "# imports for evaluation\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "class SegmentedDataset(Dataset):\n",
    "    def __init__(self, embeddings_path, csv_path):\n",
    "        # embeddings_path: path to .npy file with a dict mapping protein IDs to lists of segment embeddings\n",
    "        # csv_path: path to CSV file with filtered labels\n",
    "        \n",
    "        # load the embeddings dictionary\n",
    "        self.embeddings_dict = np.load(embeddings_path, allow_pickle=True).item()\n",
    "        \n",
    "        # Load CSV with GO annotations\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # keep only rows where Entry exists in embeddings and has at least one segment\n",
    "        self.df = self.df[self.df[\"Entry\"].isin(self.embeddings_dict)]\n",
    "        self.df = self.df[self.df[\"Entry\"].apply(lambda x: len(self.embeddings_dict[x]) > 0)]\n",
    "        \n",
    "        # ensure the molecular_functions column is parsed correctly\n",
    "        def parse_str(s):\n",
    "            if isinstance(s, str):\n",
    "                try:\n",
    "                    return ast.literal_eval(s)\n",
    "                except Exception:\n",
    "                    return [item.strip() for item in s.split(';')]\n",
    "            return []\n",
    "        \n",
    "        self.df[\"molecular_functions\"] = self.df[\"molecular_functions\"].apply(parse_str)\n",
    "        self.entries = self.df[\"Entry\"].tolist()\n",
    "\n",
    "        # create multi-label binarized labels\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.labels = self.mlb.fit_transform(self.df[\"molecular_functions\"])\n",
    "        # self.num_classes = self.labels.shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.entries[idx]\n",
    "        seg_list = self.embeddings_dict[entry]\n",
    "        seg_tensors = [torch.tensor(seg, dtype=torch.float) for seg in seg_list]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return seg_tensors, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # this collate function pads sequences of segment embeddings for each protein\n",
    "    seg_lists, labels = zip(*batch)\n",
    "\n",
    "    # pad to max segments\n",
    "    padded = pad_sequence([torch.stack(seg) for seg in seg_lists], batch_first=True)  # (B, S_max, emb_dim)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    # mask: true where padding\n",
    "    B, S, _ = padded.shape\n",
    "    mask = torch.zeros(B, S, dtype=torch.bool)\n",
    "\n",
    "    for i, seg in enumerate(seg_lists):\n",
    "        if len(seg)<S:\n",
    "            mask[i, len(seg):] = True\n",
    "    return padded, labels, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1fb827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at end of each training iteration\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b3e441",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, nhead=4, num_classes=50, num_layers=3, dim_feedforward=256, dropout=0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "\n",
    "        d_model = input_dim\n",
    "\n",
    "        # stack of transformer encoders\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=False)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        \n",
    "    def forward(self, x, pad_mask):\n",
    "        x = x.transpose(0,1) # (S, B, d_model)\n",
    "        x = self.encoder(x, src_key_padding_mask=pad_mask)\n",
    "        x = x.transpose(0,1) # (B, S, d_model)\n",
    "\n",
    "        # mask out padding then mean-pool\n",
    "        mask = (~pad_mask).unsqueeze(-1) # (B, S, 1)\n",
    "        x = x * mask\n",
    "        x = x.sum(dim=1) / mask.sum(dim=1) # (B, d_model)\n",
    "        \n",
    "        return self.classifier(x)\n",
    "    \n",
    "def train_model(model, dataloader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        y_true_all = []\n",
    "        y_pred_all = []\n",
    "\n",
    "        for batch in dataloader:\n",
    "            inputs, labels, pad_mask = batch\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pad_mask = pad_mask.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, pad_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # collect for metrics\n",
    "            with torch.no_grad():\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                preds = (probs > 0.5).long()\n",
    "                y_true_all.append(labels.cpu().numpy())\n",
    "                y_pred_all.append(preds.cpu().numpy())\n",
    "            \n",
    "        avg_loss = epoch_loss / len(dataloader.dataset)\n",
    "\n",
    "        y_true = np.vstack(y_true_all)\n",
    "        y_pred = np.vstack(y_pred_all)\n",
    "\n",
    "        acc = (y_true == y_pred).all(axis=1).mean()\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "        precision = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "        # flatten for sklearn's balanced accuracy, each class instance as one sample\n",
    "        balanced_acc = balanced_accuracy_score(y_true.flatten(), y_pred.flatten())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Subset Accuracy: {acc:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f} | F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | Balanced Acc: {balanced_acc:.4f}\")\n",
    "\n",
    "def evaluate_model(model, dataloader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    total_loss = 0.0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, pad_mask in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pad_mask = pad_mask.to(device)\n",
    "\n",
    "            outputs = model(inputs, pad_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > threshold).long()\n",
    "\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "\n",
    "    # confusion matrices for first 10 GO classes\n",
    "    classes = dataloader.dataset.mlb.classes_\n",
    "    for i in range(min(10, y_true.shape[1])):\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true[:,i], y_pred[:,i]).ravel()\n",
    "        print(f\"[{i:2d}] {classes[i]}\")\n",
    "        print(f\"    TN={tn:5d}  FP={fp:5d}  FN={fn:5d}  TP={tp:5d}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac9ab89d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 10540 proteins\n",
      "Number of classes: 50\n",
      "Using GPU: Tesla T4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/predicting-protein-function-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is on: cuda:0\n",
      "Epoch 1/10 | Subset Accuracy: 0.0302\n",
      "Epoch 1/10 | Loss: 0.7513 | F1: 0.2907 | Precision: 0.1899 | Recall: 0.8199 | Balanced Acc: 0.7882\n",
      "Epoch 2/10 | Subset Accuracy: 0.0461\n",
      "Epoch 2/10 | Loss: 0.5745 | F1: 0.4241 | Precision: 0.3043 | Recall: 0.8731 | Balanced Acc: 0.8484\n",
      "Epoch 3/10 | Subset Accuracy: 0.0523\n",
      "Epoch 3/10 | Loss: 0.5310 | F1: 0.4494 | Precision: 0.3279 | Recall: 0.8830 | Balanced Acc: 0.8603\n",
      "Epoch 4/10 | Subset Accuracy: 0.0606\n",
      "Epoch 4/10 | Loss: 0.4868 | F1: 0.4850 | Precision: 0.3622 | Recall: 0.8997 | Balanced Acc: 0.8749\n",
      "Epoch 5/10 | Subset Accuracy: 0.0647\n",
      "Epoch 5/10 | Loss: 0.4666 | F1: 0.4905 | Precision: 0.3664 | Recall: 0.9011 | Balanced Acc: 0.8793\n",
      "Epoch 6/10 | Subset Accuracy: 0.0692\n",
      "Epoch 6/10 | Loss: 0.4334 | F1: 0.5124 | Precision: 0.3875 | Recall: 0.9136 | Balanced Acc: 0.8891\n",
      "Epoch 7/10 | Subset Accuracy: 0.0732\n",
      "Epoch 7/10 | Loss: 0.4008 | F1: 0.5293 | Precision: 0.4035 | Recall: 0.9190 | Balanced Acc: 0.8968\n",
      "Epoch 8/10 | Subset Accuracy: 0.0819\n",
      "Epoch 8/10 | Loss: 0.3841 | F1: 0.5402 | Precision: 0.4145 | Recall: 0.9230 | Balanced Acc: 0.9011\n",
      "Epoch 9/10 | Subset Accuracy: 0.0815\n",
      "Epoch 9/10 | Loss: 0.3644 | F1: 0.5527 | Precision: 0.4264 | Recall: 0.9311 | Balanced Acc: 0.9068\n",
      "Epoch 10/10 | Subset Accuracy: 0.0917\n",
      "Epoch 10/10 | Loss: 0.3574 | F1: 0.5468 | Precision: 0.4176 | Recall: 0.9327 | Balanced Acc: 0.9095\n",
      "[ 0] 3-phosphoinositide-dependent protein kinase activity [GO:0004676]\n",
      "    TN=10102  FP=  193  FN=    0  TP=  245\n",
      "\n",
      "[ 1] AMP-activated protein kinase activity [GO:0004679]\n",
      "    TN=10093  FP=  200  FN=    0  TP=  247\n",
      "\n",
      "[ 2] ATP binding [GO:0005524]\n",
      "    TN= 8779  FP=  284  FN=   41  TP= 1436\n",
      "\n",
      "[ 3] ATP hydrolysis activity [GO:0016887]\n",
      "    TN= 9887  FP=  236  FN=    4  TP=  413\n",
      "\n",
      "[ 4] DNA binding [GO:0003677]\n",
      "    TN= 6622  FP= 2988  FN=   50  TP=  880\n",
      "\n",
      "[ 5] DNA-binding transcription activator activity, RNA polymerase II-specific [GO:0001228]\n",
      "    TN= 9122  FP=  943  FN=    3  TP=  472\n",
      "\n",
      "[ 6] DNA-binding transcription factor activity [GO:0003700]\n",
      "    TN= 8993  FP= 1061  FN=    4  TP=  482\n",
      "\n",
      "[ 7] DNA-binding transcription factor activity, RNA polymerase II-specific [GO:0000981]\n",
      "    TN= 9034  FP=  266  FN=   11  TP= 1229\n",
      "\n",
      "[ 8] DNA-binding transcription repressor activity, RNA polymerase II-specific [GO:0001227]\n",
      "    TN= 9217  FP= 1057  FN=    3  TP=  263\n",
      "\n",
      "[ 9] DNA-dependent protein kinase activity [GO:0004677]\n",
      "    TN=10101  FP=  193  FN=    0  TP=  246\n",
      "\n",
      "Model saved as protein_transformer_model_3_layers.pt\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # set file paths\n",
    "    embeddings_path = \"Data/esm2_segmented_embeddings.npy\"\n",
    "    csv_path = \"Data/filtered_parsed_data.csv\"\n",
    "    \n",
    "    # create dataset and dataloader\n",
    "    dataset = SegmentedDataset(embeddings_path, csv_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    print(f\"Dataset size: {len(dataset)} proteins\")\n",
    "    print(f\"Number of classes: {dataset.labels.shape[1]}\")\n",
    "    \n",
    "    # get input dimension from one sample\n",
    "    sample_segments, _ = dataset[0]\n",
    "    input_dim = sample_segments[0].shape[0]\n",
    "    \n",
    "    # instantiate transformer classifier model\n",
    "    model = TransformerClassifier(input_dim=input_dim, nhead=4, num_classes=dataset.labels.shape[1], num_layers=3, dim_feedforward=256, dropout=0.1)\n",
    "    \n",
    "    # use CUDA if available, AWS EC2 with GPU\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"model is on: {next(model.parameters()).device}\")\n",
    "\n",
    "    # set up loss function and optimizer for multi-label classification\n",
    "    # compute class weights\n",
    "    label_counts = dataset.labels.sum(axis=0)  # positive counts per class\n",
    "    total_counts = len(dataset)  # total samples\n",
    "\n",
    "    # avoid division by zero\n",
    "    pos_weights = (total_counts - label_counts) / (label_counts + 1e-5)\n",
    "    class_weights_tensor = torch.tensor(pos_weights, dtype=torch.float).to(device)\n",
    "\n",
    "    # weighted loss\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    # train the model\n",
    "    train_model(model, dataloader, criterion, optimizer, device, num_epochs=10)\n",
    "    evaluate_model(model, dataloader, device)\n",
    "    \n",
    "    # save the trained model state\n",
    "    torch.save(model.state_dict(), \"protein_transformer_model_3_layers.pt\")\n",
    "    print(\"Model saved as protein_transformer_model_3_layers.pt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
