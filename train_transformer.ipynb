{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fe92b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.12/site-packages (2.7.0)\n",
      "Requirement already satisfied: transformers in ./.venv/lib/python3.12/site-packages (4.51.3)\n",
      "Requirement already satisfied: fair-esm in ./.venv/lib/python3.12/site-packages (2.0.0)\n",
      "Requirement already satisfied: biopython in ./.venv/lib/python3.12/site-packages (1.85)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in ./.venv/lib/python3.12/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.12/site-packages (from torch) (79.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in ./.venv/lib/python3.12/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.12/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.12/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.5.1.17 in ./.venv/lib/python3.12/site-packages (from torch) (9.5.1.17)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in ./.venv/lib/python3.12/site-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in ./.venv/lib/python3.12/site-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in ./.venv/lib/python3.12/site-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in ./.venv/lib/python3.12/site-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in ./.venv/lib/python3.12/site-packages (from torch) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in ./.venv/lib/python3.12/site-packages (from torch) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in ./.venv/lib/python3.12/site-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in ./.venv/lib/python3.12/site-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.3.0 in ./.venv/lib/python3.12/site-packages (from torch) (3.3.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in ./.venv/lib/python3.12/site-packages (from transformers) (0.30.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.12/site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./.venv/lib/python3.12/site-packages (from transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in ./.venv/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.15.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./.venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests->transformers) (2025.1.31)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch transformers fair-esm biopython scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bd7454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Tesla T4\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())  # should return true\n",
    "print(torch.cuda.get_device_name(0))  # should say T4\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import ast  # parses string representations\n",
    "\n",
    "# imports for evaluation\n",
    "from sklearn.metrics import (\n",
    "    balanced_accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71f1287e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SegmentedDataset(Dataset):\n",
    "    def __init__(self, embeddings_path, csv_path):\n",
    "        # embeddings_path: path to .npy file with a dict mapping protein IDs to lists of segment embeddings\n",
    "        # csv_path: path to CSV file with filtered labels\n",
    "        \n",
    "        # load the embeddings dictionary\n",
    "        self.embeddings_dict = np.load(embeddings_path, allow_pickle=True).item()\n",
    "        \n",
    "        # Load CSV with GO annotations\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # keep only rows where Entry exists in embeddings and has at least one segment\n",
    "        self.df = self.df[self.df[\"Entry\"].isin(self.embeddings_dict)]\n",
    "        self.df = self.df[self.df[\"Entry\"].apply(lambda x: len(self.embeddings_dict[x]) > 0)]\n",
    "        \n",
    "        # ensure the molecular_functions column is parsed correctly\n",
    "        def parse_str(s):\n",
    "            if isinstance(s, str):\n",
    "                try:\n",
    "                    return ast.literal_eval(s)\n",
    "                except Exception:\n",
    "                    return [item.strip() for item in s.split(';')]\n",
    "            return []\n",
    "        \n",
    "        self.df[\"molecular_functions\"] = self.df[\"molecular_functions\"].apply(parse_str)\n",
    "        self.entries = self.df[\"Entry\"].tolist()\n",
    "\n",
    "        # create multi-label binarized labels\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.labels = self.mlb.fit_transform(self.df[\"molecular_functions\"])\n",
    "        # self.num_classes = self.labels.shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.entries[idx]\n",
    "        seg_list = self.embeddings_dict[entry]\n",
    "        seg_tensors = [torch.tensor(seg, dtype=torch.float) for seg in seg_list]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return seg_tensors, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # this collate function pads sequences of segment embeddings for each protein\n",
    "    seg_lists, labels = zip(*batch)\n",
    "\n",
    "    # pad to max segments\n",
    "    padded = pad_sequence([torch.stack(seg) for seg in seg_lists], batch_first=True)  # (B, S_max, emb_dim)\n",
    "    labels = torch.stack(labels)\n",
    "\n",
    "    # mask: true where padding\n",
    "    B, S, _ = padded.shape\n",
    "    mask = torch.zeros(B, S, dtype=torch.bool)\n",
    "\n",
    "    for i, seg in enumerate(seg_lists):\n",
    "        if len(seg)<S:\n",
    "            mask[i, len(seg):] = True\n",
    "    return padded, labels, mask\n",
    "\n",
    "class TransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, nhead=4, num_classes=50, dim_feedforward=256, dropout=0.1):\n",
    "        super(TransformerClassifier, self).__init__()\n",
    "\n",
    "        d_model = input_dim\n",
    "\n",
    "        # 1-layer transformer encoder\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=False) \n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)\n",
    "        self.classifier = nn.Linear(d_model, num_classes)\n",
    "        \n",
    "    def forward(self, x, pad_mask):\n",
    "        x = x.transpose(0,1) # (S, B, d_model)\n",
    "        x = self.encoder(x, src_key_padding_mask=pad_mask)\n",
    "        x = x.transpose(0,1) # (B, S, d_model)\n",
    "\n",
    "        # mask out padding then mean-pool\n",
    "        mask = (~pad_mask).unsqueeze(-1) # (B, S, 1)\n",
    "        x = x * mask\n",
    "        x = x.sum(dim=1) / mask.sum(dim=1) # (B, d_model)\n",
    "        \n",
    "        return self.classifier(x)\n",
    "    \n",
    "def train_model(model, dataloader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "        y_true_all = []\n",
    "        y_pred_all = []\n",
    "\n",
    "        for batch in dataloader:\n",
    "            inputs, labels, pad_mask = batch\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pad_mask = pad_mask.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, pad_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            # collect for metrics\n",
    "            with torch.no_grad():\n",
    "                probs = torch.sigmoid(outputs)\n",
    "                preds = (probs > 0.5).long()\n",
    "                y_true_all.append(labels.cpu().numpy())\n",
    "                y_pred_all.append(preds.cpu().numpy())\n",
    "            \n",
    "        avg_loss = epoch_loss / len(dataloader.dataset)\n",
    "\n",
    "        y_true = np.vstack(y_true_all)\n",
    "        y_pred = np.vstack(y_pred_all)\n",
    "\n",
    "        acc = (y_true == y_pred).all(axis=1).mean()\n",
    "\n",
    "        f1 = f1_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "        precision = precision_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "        recall = recall_score(y_true, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "        # flatten for sklearn's balanced accuracy, each class instance as one sample\n",
    "        balanced_acc = balanced_accuracy_score(y_true.flatten(), y_pred.flatten())\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Subset Accuracy: {acc:.4f}\")\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs} | Loss: {avg_loss:.4f} | F1: {f1:.4f} | Precision: {precision:.4f} | Recall: {recall:.4f} | Balanced Acc: {balanced_acc:.4f}\")\n",
    "\n",
    "def evaluate_model(model, dataloader, device, threshold=0.5):\n",
    "    model.eval()\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "    total_loss = 0.0\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels, pad_mask in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pad_mask = pad_mask.to(device)\n",
    "\n",
    "            outputs = model(inputs, pad_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            probs = torch.sigmoid(outputs)\n",
    "            preds = (probs > threshold).long()\n",
    "\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "\n",
    "    y_true = np.vstack(all_labels)\n",
    "    y_pred = np.vstack(all_preds)\n",
    "\n",
    "    # confusion matrices for first 10 GO classes\n",
    "    classes = dataloader.dataset.mlb.classes_\n",
    "    for i in range(min(10, y_true.shape[1])):\n",
    "        tn, fp, fn, tp = confusion_matrix(y_true[:,i], y_pred[:,i]).ravel()\n",
    "        print(f\"[{i:2d}] {classes[i]}\")\n",
    "        print(f\"    TN={tn:5d}  FP={fp:5d}  FN={fn:5d}  TP={tp:5d}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "72c18caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset size: 10540 proteins\n",
      "Number of classes: 50\n",
      "Using GPU: Tesla T4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/predicting-protein-function-thesis/.venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:382: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model is on: cuda:0\n",
      "Epoch 1/10 | Subset Accuracy: 0.0312\n",
      "Epoch 1/10 | Loss: 0.8183 | F1: 0.2628 | Precision: 0.1719 | Recall: 0.7936 | Balanced Acc: 0.7657\n",
      "Epoch 2/10 | Subset Accuracy: 0.0462\n",
      "Epoch 2/10 | Loss: 0.5734 | F1: 0.4376 | Precision: 0.3173 | Recall: 0.8725 | Balanced Acc: 0.8470\n",
      "Epoch 3/10 | Subset Accuracy: 0.0546\n",
      "Epoch 3/10 | Loss: 0.5128 | F1: 0.4725 | Precision: 0.3509 | Recall: 0.8889 | Balanced Acc: 0.8652\n",
      "Epoch 4/10 | Subset Accuracy: 0.0651\n",
      "Epoch 4/10 | Loss: 0.4751 | F1: 0.4951 | Precision: 0.3728 | Recall: 0.8985 | Balanced Acc: 0.8754\n",
      "Epoch 5/10 | Subset Accuracy: 0.0647\n",
      "Epoch 5/10 | Loss: 0.4446 | F1: 0.5144 | Precision: 0.3920 | Recall: 0.9069 | Balanced Acc: 0.8843\n",
      "Epoch 6/10 | Subset Accuracy: 0.0762\n",
      "Epoch 6/10 | Loss: 0.4182 | F1: 0.5310 | Precision: 0.4090 | Recall: 0.9135 | Balanced Acc: 0.8913\n",
      "Epoch 7/10 | Subset Accuracy: 0.0792\n",
      "Epoch 7/10 | Loss: 0.3953 | F1: 0.5420 | Precision: 0.4189 | Recall: 0.9207 | Balanced Acc: 0.8976\n",
      "Epoch 8/10 | Subset Accuracy: 0.0827\n",
      "Epoch 8/10 | Loss: 0.3786 | F1: 0.5425 | Precision: 0.4164 | Recall: 0.9266 | Balanced Acc: 0.9031\n",
      "Epoch 9/10 | Subset Accuracy: 0.0904\n",
      "Epoch 9/10 | Loss: 0.3516 | F1: 0.5653 | Precision: 0.4406 | Recall: 0.9344 | Balanced Acc: 0.9097\n",
      "Epoch 10/10 | Subset Accuracy: 0.0947\n",
      "Epoch 10/10 | Loss: 0.3356 | F1: 0.5794 | Precision: 0.4552 | Recall: 0.9399 | Balanced Acc: 0.9145\n",
      "[ 0] 3-phosphoinositide-dependent protein kinase activity [GO:0004676]\n",
      "    TN=10130  FP=  165  FN=    0  TP=  245\n",
      "\n",
      "[ 1] AMP-activated protein kinase activity [GO:0004679]\n",
      "    TN=10116  FP=  177  FN=    0  TP=  247\n",
      "\n",
      "[ 2] ATP binding [GO:0005524]\n",
      "    TN= 8775  FP=  288  FN=   57  TP= 1420\n",
      "\n",
      "[ 3] ATP hydrolysis activity [GO:0016887]\n",
      "    TN= 9882  FP=  241  FN=    3  TP=  414\n",
      "\n",
      "[ 4] DNA binding [GO:0003677]\n",
      "    TN= 7107  FP= 2503  FN=   94  TP=  836\n",
      "\n",
      "[ 5] DNA-binding transcription activator activity, RNA polymerase II-specific [GO:0001228]\n",
      "    TN= 9040  FP= 1025  FN=    2  TP=  473\n",
      "\n",
      "[ 6] DNA-binding transcription factor activity [GO:0003700]\n",
      "    TN= 8937  FP= 1117  FN=    1  TP=  485\n",
      "\n",
      "[ 7] DNA-binding transcription factor activity, RNA polymerase II-specific [GO:0000981]\n",
      "    TN= 9003  FP=  297  FN=    7  TP= 1233\n",
      "\n",
      "[ 8] DNA-binding transcription repressor activity, RNA polymerase II-specific [GO:0001227]\n",
      "    TN= 9036  FP= 1238  FN=    0  TP=  266\n",
      "\n",
      "[ 9] DNA-dependent protein kinase activity [GO:0004677]\n",
      "    TN=10129  FP=  165  FN=    0  TP=  246\n",
      "\n",
      "Model saved as protein_transformer_model.pt\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # set file paths\n",
    "    embeddings_path = \"Data/esm2_segmented_embeddings.npy\"\n",
    "    csv_path = \"Data/filtered_parsed_data.csv\"\n",
    "    \n",
    "    # create dataset and dataloader\n",
    "    dataset = SegmentedDataset(embeddings_path, csv_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    print(f\"Dataset size: {len(dataset)} proteins\")\n",
    "    print(f\"Number of classes: {dataset.labels.shape[1]}\")\n",
    "    \n",
    "    # get input dimension from one sample\n",
    "    sample_segments, _ = dataset[0]\n",
    "    input_dim = sample_segments[0].shape[0]\n",
    "    \n",
    "    # instantiate transformer classifier model\n",
    "    model = TransformerClassifier(input_dim=input_dim, nhead=4, num_classes=dataset.labels.shape[1], dim_feedforward=256, dropout=0.1)\n",
    "    \n",
    "    # use CUDA if available, AWS EC2 with GPU\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device(\"cuda\")\n",
    "        print(\"Using GPU:\", torch.cuda.get_device_name(0))\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "        print(\"Using CPU\")\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    print(f\"model is on: {next(model.parameters()).device}\")\n",
    "\n",
    "    # set up loss function and optimizer for multi-label classification\n",
    "    # compute class weights\n",
    "    label_counts = dataset.labels.sum(axis=0)  # positive counts per class\n",
    "    total_counts = len(dataset)  # total samples\n",
    "\n",
    "    # avoid division by zero\n",
    "    pos_weights = (total_counts - label_counts) / (label_counts + 1e-5)\n",
    "    class_weights_tensor = torch.tensor(pos_weights, dtype=torch.float).to(device)\n",
    "\n",
    "    # weighted loss\n",
    "    criterion = nn.BCEWithLogitsLoss(pos_weight=class_weights_tensor)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    # train the model\n",
    "    train_model(model, dataloader, criterion, optimizer, device, num_epochs=10)\n",
    "    evaluate_model(model, dataloader, device)\n",
    "    \n",
    "    # save the trained model state\n",
    "    torch.save(model.state_dict(), \"protein_transformer_model.pt\")\n",
    "    print(\"Model saved as protein_transformer_model.pt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
