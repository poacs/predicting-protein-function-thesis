{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avoid out-of-memory errors during training\n",
    "import os\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/poa/Library/Python/3.9/lib/python/site-packages (2.6.0)\n",
      "Requirement already satisfied: transformers in /Users/poa/Library/Python/3.9/lib/python/site-packages (4.49.0)\n",
      "Requirement already satisfied: fair-esm in /Users/poa/Library/Python/3.9/lib/python/site-packages (2.0.0)\n",
      "Requirement already satisfied: biopython in /Users/poa/Library/Python/3.9/lib/python/site-packages (1.85)\n",
      "Requirement already satisfied: scikit-learn in /Users/poa/Library/Python/3.9/lib/python/site-packages (1.6.1)\n",
      "Requirement already satisfied: networkx in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: fsspec in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (2025.2.0)\n",
      "Requirement already satisfied: filelock in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: jinja2 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from transformers) (2.0.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/poa/Library/Python/3.9/lib/python/site-packages (from requests->transformers) (3.4.1)\n",
      "\u001b[33mWARNING: You are using pip version 21.2.4; however, version 25.0.1 is available.\n",
      "You should consider upgrading via the '/Library/Developer/CommandLineTools/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install torch transformers fair-esm biopython scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from collections import Counter\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import ast  # parses string representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinDataset(Dataset):\n",
    "    def __init__(self, embeddings_path, csv_path):\n",
    "        # embeddings_path: path to .npy file with a dict mapping protein IDs to lists of segment embeddings\n",
    "        # csv_path: path to CSV file with filtered labels\n",
    "        \n",
    "        # Load the embeddings dictionary\n",
    "        self.embeddings_dict = np.load(embeddings_path, allow_pickle=True).item()\n",
    "        \n",
    "        # Load CSV with GO annotations\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        \n",
    "        # keep only rows where Entry exists in embeddings and has at least one segment\n",
    "        self.df = self.df[self.df[\"Entry\"].isin(self.embeddings_dict.keys())].reset_index(drop=True)\n",
    "        self.df = self.df[self.df[\"Entry\"].apply(lambda x: len(self.embeddings_dict[x]) > 0)]\n",
    "        self.entries = self.df[\"Entry\"].tolist()\n",
    "        \n",
    "        # ensure the molecular_functions column is parsed correctly\n",
    "        def parse_str(s):\n",
    "            if isinstance(s, str):\n",
    "                try:\n",
    "                    return ast.literal_eval(s)\n",
    "                except Exception:\n",
    "                    return [item.strip() for item in s.split(';') if item.strip()]\n",
    "            return s\n",
    "        \n",
    "        self.df[\"molecular_functions\"] = self.df[\"molecular_functions\"].apply(parse_str)\n",
    "        \n",
    "        # create multi-label binarized labels\n",
    "        self.mlb = MultiLabelBinarizer()\n",
    "        self.labels = self.mlb.fit_transform(self.df[\"molecular_functions\"])\n",
    "        self.num_classes = self.labels.shape[1]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.entries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        entry = self.entries[idx]\n",
    "        seg_list = self.embeddings_dict[entry]\n",
    "        seg_tensors = [torch.tensor(seg, dtype=torch.float) for seg in seg_list]\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return seg_tensors, label\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # this collate function pads sequences of segment embeddings for each protein\n",
    "    all_segments = []\n",
    "    labels = []\n",
    "    lengths = []\n",
    "\n",
    "    for seg_tensors, label in batch:\n",
    "        lengths.append(len(seg_tensors))\n",
    "        all_segments.append(torch.stack(seg_tensors))  # num_segments, embedding_dim\n",
    "        labels.append(label)\n",
    "\n",
    "    padded_segments = pad_sequence(all_segments, batch_first=True)  # batch_size, max_seq_len, embedding_dim\n",
    "    labels = torch.stack(labels)\n",
    "    batch_size, max_seq_len, _ = padded_segments.size()\n",
    "    pad_mask = torch.zeros((batch_size, max_seq_len), dtype=torch.bool)\n",
    "\n",
    "    for i, l in enumerate(lengths):\n",
    "        if l < max_seq_len:\n",
    "            pad_mask[i, l:] = True\n",
    "    return padded_segments, labels, pad_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinTransformerClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes, num_layers=2, nhead=8, dim_feedforward=2048, dropout=0.1):\n",
    "        super(ProteinTransformerClassifier, self).__init__()\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=input_dim, nhead=nhead, \n",
    "                                                   dim_feedforward=dim_feedforward, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "        self.classifier = nn.Linear(input_dim, num_classes)\n",
    "        \n",
    "    def forward(self, x, src_key_padding_mask):\n",
    "        # x: batch_size, seq_len, input_dim\n",
    "        x = x.transpose(0, 1)  # seq_len, batch_size, input_dim\n",
    "        x = self.transformer_encoder(x, src_key_padding_mask=src_key_padding_mask)\n",
    "        x = x.transpose(0, 1)  # batch_size, seq_len, input_dim\n",
    "        mask = (~src_key_padding_mask).unsqueeze(-1).float()  # batch_size, seq_len, 1\n",
    "        x = x * mask\n",
    "        pooled = x.sum(dim=1) / mask.sum(dim=1)  # batch_size, input_dim\n",
    "        logits = self.classifier(pooled)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, criterion, optimizer, device, num_epochs=10):\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0.0\n",
    "\n",
    "        for batch in dataloader:\n",
    "            inputs, labels, pad_mask = batch\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            pad_mask = pad_mask.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs, src_key_padding_mask=pad_mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "        avg_loss = epoch_loss / len(dataloader.dataset)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/esm2_segmented_embeddings.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel saved as protein_transformer_model.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m---> 39\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m, in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m csv_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata/filtered_parsed_data.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Create dataset and dataloader\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mProteinDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m dataloader \u001b[38;5;241m=\u001b[39m DataLoader(dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_fn)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataset size: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m proteins\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m, in \u001b[0;36mProteinDataset.__init__\u001b[0;34m(self, embeddings_path, csv_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, embeddings_path, csv_path):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# embeddings_path: path to .npy file with a dict mapping protein IDs to lists of segment embeddings\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# csv_path: path to CSV file with filtered labels\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Load the embeddings dictionary\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings_dict \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43membeddings_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;66;03m# Load CSV with GO annotations\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_path)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/numpy/lib/_npyio_impl.py:455\u001b[0m, in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    453\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 455\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    456\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    458\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/esm2_segmented_embeddings.npy'"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # set file paths\n",
    "    embeddings_path = \"data/esm2_segmented_embeddings.npy\"\n",
    "    csv_path = \"data/filtered_parsed_data.csv\"\n",
    "    \n",
    "    # Create dataset and dataloader\n",
    "    dataset = ProteinDataset(embeddings_path, csv_path)\n",
    "    dataloader = DataLoader(dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "    \n",
    "    print(f\"Dataset size: {len(dataset)} proteins\")\n",
    "    print(f\"Number of classes: {dataset.num_classes}\")\n",
    "    \n",
    "    # get input dimension from one sample (assume at least one segment exists)\n",
    "    sample_segments, _ = dataset[0]\n",
    "    input_dim = sample_segments[0].shape[0]\n",
    "    \n",
    "    # instantiate transformer classifier model\n",
    "    model = ProteinTransformerClassifier(input_dim=input_dim, num_classes=dataset.num_classes)\n",
    "    \n",
    "    # Use Apple's MPS backend\n",
    "    if torch.backends.mps.is_available():\n",
    "        device = torch.device(\"mps\")\n",
    "    else:\n",
    "        device = torch.device(\"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    # set up loss function and optimizer for multi-label classification\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    \n",
    "    # train the model\n",
    "    train_model(model, dataloader, criterion, optimizer, device, num_epochs=10)\n",
    "    \n",
    "    # save the trained model state\n",
    "    torch.save(model.state_dict(), \"protein_transformer_model.pt\")\n",
    "    print(\"Model saved as protein_transformer_model.pt\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
